#!/bin/sh

###########################################
#                                         #
# MANAGED BY PUPPET                       #
#                                         #
# Manual changes WILL be overwritten      #
#                                         #
###########################################

user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:25.0) Gecko/20100101 Firefox/25.0'
backup_dir="/srv/nfs/io/websites"
conf_file="/etc/nitelite/websitelist"

# Strip comments and empty lines from the config file
DATA=$(cat $conf_file | grep -v "^#" | grep -v "^$" | sed -e 's:#.*::g');

if [ ! -d "$backup_dir" ]; then
  mkdir -p "$backup_dir"
fi

while read -r line; do

  # VARIABLES FOR MIRROR COMMAND
  #
  # site_name - the web site name minus protocol and www; used as parent 
  # directory for snapshots
  #
  # latest_dir - the most recent snapshot for the current website. if it 
  # exists, a copy will be created with hard links. then an update will take 
  # place to ensure only updated files get downloaded. This avoids duplication 
  # of files while retaining an accurate copy of a snapshot for a given date.
  #
  # mirror_dir - the absolute directory path for the snapshot that is about 
  # to be created. this will contains a hard-linked version of the latest 
  # snapshot (if the latest snapshot exists). Then the mirror command will 
  # update this directory, so all other snapshots are preserved.

  # Remove protocol prefix if it exists
  site_name=`printf "$line" | sed -E 's/(https?:\/\/)?(www\.)?//g'`
  latest_dir=""

  if [ ! -d "$backup_dir/$site_name" ]; then
    mkdir -p "$backup_dir/$site_name"
  else

    # We're depending on how ls sorts dates of the form: YYYY-MM-DD
    # for this to work properly
    latest_dir="$backup_dir/$site_name/$(ls $backup_dir/$site_name | tail -1)"
  fi

  mirror_dir="$backup_dir/$site_name/`date +\%F`"

  printf "LINE: $line\n"
  printf "URL: $site_name\n"
  printf "Most Recent Mirror: $latest_dir\n"
  printf "New Mirror Path: $mirror_dir\n"

  # NOTE: Since this is a rare op, I'm doing these manually. The code below is 
  # for reference.

  # if [ -n "$latest_dir" ]; then
  #   printf "$latest_dir exists. Hard linking..."
  #
  #   # mac can't use regular old cp, so use gcp
  #   #gcp -al "$latest_dir" "$mirror_dir"
  #   cp -al "$latest_dir" "$mirror_dir"
  # else
  #   mkdir -p "$mirror_dir"
  # fi
  #
  # # -sN 0 - never follow robots.txt and meta robots tags
  # httrack "$line" -O "$mirror_dir" -R5s0zZvDnr50c1 -F "$user_agent" "+*.$site_name/*"

done <<< "$DATA"

